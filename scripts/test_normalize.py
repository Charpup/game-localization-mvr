#!/usr/bin/env python3
"""
æµ‹è¯• normalize_guard.py è„šæœ¬
éªŒè¯å ä½ç¬¦å†»ç»“åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import csv
import json
import sys
from pathlib import Path


def test_normalize_guard():
    """æµ‹è¯• normalize_guard è¾“å‡º"""
    
    print("ğŸ§ª Testing normalize_guard.py output...")
    print()
    
    # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    draft_path = Path("data/draft_output.csv")
    map_path = Path("data/placeholder_map_output.json")
    
    if not draft_path.exists():
        print("âŒ Error: draft_output.csv not found")
        return False
    
    if not map_path.exists():
        print("âŒ Error: placeholder_map_output.json not found")
        return False
    
    print("âœ… Output files exist")
    
    # è¯»å– draft CSV
    with open(draft_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        rows = list(reader)
    
    print(f"âœ… Loaded {len(rows)} rows from draft CSV")
    
    # è¯»å– placeholder map
    with open(map_path, 'r', encoding='utf-8') as f:
        map_data = json.load(f)
    
    mappings = map_data.get('mappings', {})
    print(f"âœ… Loaded {len(mappings)} placeholder mappings")
    print()
    
    # éªŒè¯æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            'string_id': 'welcome_msg',
            'expected_tokens': ['âŸ¦PH_1âŸ§'],
            'expected_mappings': {'PH_1': '{0}'}
        },
        {
            'string_id': 'color_text',
            'expected_tokens': ['âŸ¦TAG_1âŸ§', 'âŸ¦TAG_2âŸ§'],
            'expected_mappings': {'TAG_1': '</color>', 'TAG_2': '<color=#FF00FF>'}
        },
        {
            'string_id': 'multi_placeholder',
            'expected_tokens': ['âŸ¦PH_4âŸ§', 'âŸ¦PH_5âŸ§', 'âŸ¦PH_6âŸ§'],
            'expected_mappings': {
                'PH_4': '{itemName}',
                'PH_5': '{location}',
                'PH_6': '{playerName}'
            }
        }
    ]
    
    all_passed = True
    
    for test in test_cases:
        string_id = test['string_id']
        expected_tokens = test['expected_tokens']
        expected_mappings = test['expected_mappings']
        
        # æ‰¾åˆ°å¯¹åº”çš„è¡Œ
        row = next((r for r in rows if r['string_id'] == string_id), None)
        
        if not row:
            print(f"âŒ Test failed: {string_id} not found in output")
            all_passed = False
            continue
        
        tokenized = row.get('tokenized_zh', '')
        
        # æ£€æŸ¥ token æ˜¯å¦å­˜åœ¨
        tokens_found = all(token in tokenized for token in expected_tokens)
        
        if not tokens_found:
            print(f"âŒ Test failed: {string_id}")
            print(f"   Expected tokens: {expected_tokens}")
            print(f"   Tokenized text: {tokenized}")
            all_passed = False
            continue
        
        # æ£€æŸ¥æ˜ å°„æ˜¯å¦æ­£ç¡®
        mappings_correct = all(
            mappings.get(key) == value
            for key, value in expected_mappings.items()
        )
        
        if not mappings_correct:
            print(f"âŒ Test failed: {string_id} - incorrect mappings")
            all_passed = False
            continue
        
        print(f"âœ… Test passed: {string_id}")
        print(f"   Tokens: {expected_tokens}")
        print(f"   Tokenized: {tokenized}")
        print()
    
    # éªŒè¯æ€»æ•°
    metadata = map_data.get('metadata', {})
    total_placeholders = metadata.get('total_placeholders', 0)
    
    if total_placeholders != 11:
        print(f"âŒ Expected 11 total placeholders, got {total_placeholders}")
        all_passed = False
    else:
        print(f"âœ… Correct total placeholder count: {total_placeholders}")
    
    print()
    
    if all_passed:
        print("ğŸ‰ All tests passed!")
        return True
    else:
        print("âŒ Some tests failed")
        return False


if __name__ == "__main__":
    success = test_normalize_guard()
    sys.exit(0 if success else 1)
