#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
repair_loop.py
Auto-repair loop for translations with hard+soft QA issues.

Purpose:
  - Read qa_hard_report.json (blocking errors) + repair_tasks.jsonl (soft QA issues)
  - Hard fail priority: fix hard QA errors first (otherwise can't ship)
  - Soft major next: only fix major severity (minor can be left for human review)
  - Validate each repair with quick checks
  - Checkpoint/resume support
  - Escalate unfixable items

Usage:
  python scripts/repair_loop.py \
    data/translated.csv data/qa_hard_report.json data/repair_tasks.jsonl \
    workflow/style_guide.md data/glossary.yaml \
    --out_csv data/repaired.csv --max_retries 4

Environment:
  LLM_BASE_URL, LLM_API_KEY, LLM_MODEL (via runtime_adapter)
"""

import argparse
import csv
import json
import re
import sys
import time
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple

# Ensure UTF-8 output on Windows
# if sys.platform == 'win32':
#     import io
#     sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
#     sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

try:
    import yaml
except Exception:
    yaml = None

from runtime_adapter import LLMClient, LLMError

TOKEN_RE = re.compile(r"âŸ¦(PH_\d+|TAG_\d+)âŸ§")
CJK_RE = re.compile(r"[\u4e00-\u9fff]")


def read_csv(p: str) -> List[Dict[str, str]]:
    """Read CSV file as list of dicts."""
    with open(p, "r", encoding="utf-8-sig", newline="") as f:
        return list(csv.DictReader(f))


def write_csv(p: str, fieldnames: List[str], rows: List[Dict[str, str]]) -> None:
    """Write CSV file."""
    Path(p).parent.mkdir(parents=True, exist_ok=True)
    with open(p, "w", encoding="utf-8-sig", newline="") as f:
        w = csv.DictWriter(f, fieldnames=fieldnames)
        w.writeheader()
        w.writerows(rows)


def append_csv(p: str, fieldnames: List[str], rows: List[Dict[str, str]]) -> None:
    """Append rows to CSV file."""
    Path(p).parent.mkdir(parents=True, exist_ok=True)
    exists = Path(p).exists()
    with open(p, "a" if exists else "w", encoding="utf-8-sig", newline="") as f:
        w = csv.DictWriter(f, fieldnames=fieldnames)
        if not exists:
            w.writeheader()
        w.writerows(rows)


def read_json(p: str) -> Any:
    """Read JSON file."""
    with open(p, "r", encoding="utf-8") as f:
        return json.load(f)


def load_text(p: str) -> str:
    """Load text file content."""
    with open(p, "r", encoding="utf-8") as f:
        return f.read().strip()


def load_yaml(p: str) -> dict:
    """Load YAML file."""
    if yaml is None:
        raise RuntimeError("PyYAML required: pip install pyyaml")
    with open(p, "r", encoding="utf-8") as f:
        return yaml.safe_load(f) or {}


def tokens_signature(text: str) -> Dict[str, int]:
    """Count tokens in text."""
    d = {}
    for m in TOKEN_RE.finditer(text or ""):
        k = m.group(1)
        d[k] = d.get(k, 0) + 1
    return d


def quick_validate(tokenized_zh: str, ru: str) -> Tuple[bool, str]:
    """
    Quick validation for repaired translation.
    Returns (is_valid, reason).
    """
    if tokens_signature(tokenized_zh) != tokens_signature(ru):
        return False, "token_mismatch"
    if CJK_RE.search(ru or ""):
        return False, "cjk_remaining"
    if not (ru or "").strip():
        return False, "empty"
    return True, "ok"


def iter_jsonl(p: str) -> List[dict]:
    """Read JSONL file as list of dicts."""
    if not p or not Path(p).exists():
        return []
    out = []
    with open(p, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                out.append(json.loads(line))
            except Exception:
                continue
    return out


def load_checkpoint(p: str) -> dict:
    """Load checkpoint file."""
    if Path(p).exists():
        return read_json(p)
    return {"done_ids": {}, "stats": {"ok": 0, "fail": 0}}


def save_checkpoint(p: str, obj: dict) -> None:
    """Save checkpoint file."""
    Path(p).parent.mkdir(parents=True, exist_ok=True)
    with open(p, "w", encoding="utf-8") as f:
        json.dump(obj, f, ensure_ascii=False, indent=2)


# Import glossary filters
from translate_llm import load_glossary, build_glossary_constraints, GlossaryEntry

def build_system(style: str) -> str:
    """Build system prompt for repair."""
    return (
        "ä½ æ˜¯æ‰‹æ¸¸æœ¬åœ°åŒ–ä¿®å¤å™¨ï¼ˆzh-CN â†’ ru-RUï¼‰ã€‚ä½ ä¼šæ ¹æ®ç»™å®šçš„é”™è¯¯/å»ºè®®ï¼Œå¯¹ target_ru è¿›è¡Œä¿®å¤ã€‚\n\n"
        "æœ¯è¯­è¡¨è§„åˆ™ï¼ˆç¡¬æ€§ï¼‰ï¼š\n"
        "- glossary ä¸­å‡ºç°çš„ term_zh â†’ term_ru å¿…é¡»ä¸¥æ ¼ä½¿ç”¨ term_ruï¼ˆå¤§å°å†™/è¯å½¢æŒ‰ glossary æŒ‡å®šï¼›å¦‚éœ€è¦å˜æ ¼è¯·ä¿æŒè¯æ ¹ä¸€è‡´å¹¶ä¼˜å…ˆä¿æŒ glossary å½¢å¼ï¼‰ã€‚\n"
        "- è‹¥æºæ–‡åŒ…å« term_zhï¼Œä½†è¯‘æ–‡éš¾ä»¥ç›´æ¥å¥—ç”¨ term_ruï¼Œå¿…é¡»åœ¨ä¸ç ´åå ä½ç¬¦çš„å‰æä¸‹æ”¹å†™å¥å­ä»¥å®¹çº³ term_ruã€‚\n\n\n"
        "å ä½ç¬¦è§„åˆ™ï¼ˆç¡¬æ€§ï¼‰ï¼š\n"
        "- ä»»ä½•å½¢å¦‚ {TOKEN} / %s / %d / ${var} / <tag> / [xxx] çš„å ä½ç¬¦å¿…é¡»åŸæ ·ä¿ç•™ï¼Œä¸å¾—ç¿»è¯‘/æ”¹åŠ¨/å¢åˆ /ç§»åŠ¨ã€‚\n"
        "- ä¸å¾—æ–°å¢ä»»ä½•å ä½ç¬¦ï¼›ä¸å¾—åˆ é™¤ä»»ä½•å ä½ç¬¦ã€‚\n"
        "- è¾“å‡ºä¸­ç¦æ­¢å‡ºç°ä¸­æ–‡æ‹¬å·ç¬¦å·ã€ã€‘ï¼›å¦‚æºæ–‡å«ã€ã€‘ç”¨äºåˆ†ç»„/å¼ºè°ƒï¼Œä¿„è¯­ä¾§ç”¨ Â«Â» æˆ–æ”¹å†™ä¸ºâ€œX: â€¦â€ã€‚\n\n\n"
        "è¾“å…¥åŒ…å«ï¼šsource_zhã€current_ruã€issuesï¼ˆå¯èƒ½æ¥è‡ª qa_hard æˆ– soft_qaï¼‰ã€‚\n"
        "è¾“å‡ºæ ¼å¼ï¼ˆç¡¬æ€§ï¼‰ï¼š\n"
        "- åªè¾“å‡ºä¿®å¤åçš„ä¿„æ–‡çº¯æ–‡æœ¬ï¼Œä¸è§£é‡Šï¼Œä¸è¦ JSONã€‚\n"
        "ä¿®å¤ä¼˜å…ˆçº§ï¼ˆä»é«˜åˆ°ä½ï¼‰ï¼š\n"
        "1) å ä½ç¬¦/æ ¼å¼ç¡¬é”™è¯¯\n"
        "2) æœ¯è¯­ä¸€è‡´æ€§ï¼ˆæŒ‰ glossaryï¼‰\n"
        "3) è¯¯è¯‘/æ¼è¯‘/æ­§ä¹‰\n"
        "4) è¯­æ°”ä¸ç®€æ´æ€§ï¼ˆåœ¨ä¸å¼•å…¥æ–°é—®é¢˜å‰æä¸‹ï¼‰\n"
    )

def build_user(row: dict, issues: List[str], glossary_entries: List[GlossaryEntry], style_guide_excerpt: str) -> str:
    """Build user prompt for repair."""
    tokenized_zh = row.get("tokenized_zh") or row.get("source_zh") or ""
    current_ru = row.get("target_text") or ""
    sid =  row.get("string_id", "")
    
    # Build glossary excerpt
    approved, banned, proposed = build_glossary_constraints(glossary_entries, tokenized_zh)
    
    glossary_lines = []
    if approved:
        glossary_lines.append("ã€å¼ºåˆ¶ä½¿ç”¨ã€‘")
        for k, v in approved.items():
            glossary_lines.append(f"- {k} â†’ {v}")
    if banned:
        glossary_lines.append("ã€ç¦æ­¢è‡ªåˆ›ã€‘")
        for k in banned:
            glossary_lines.append(f"- {k}")
            
    glossary_text = "\n".join(glossary_lines) if glossary_lines else "(æ— )"

    # Format issues list
    issues_text = "\n".join([f"- {i}" for i in issues])

    return (
        f"string_id: {sid}\n"
        f"source_zh: {tokenized_zh}\n"
        f"current_ru: {current_ru}\n\n"
        "issues:\n"
        f"{issues_text}\n\n"
        "glossary_excerpt:\n"
        f"{glossary_text}\n\n"
        "style_guide_excerpt:\n"
        f"{style_guide_excerpt[:2000]}\n"
    )



def main():
    ap = argparse.ArgumentParser(description="Auto-repair loop for translations")
    ap.add_argument("translated_csv", help="Input translated.csv")
    ap.add_argument("qa_hard_report_json", help="Hard QA report (qa_hard_report.json)")
    ap.add_argument("repair_tasks_jsonl", help="Soft QA repair tasks (repair_tasks.jsonl)")
    ap.add_argument("style_guide_md", help="Style guide file")
    ap.add_argument("glossary_yaml", help="Glossary file", nargs="?", default="")
    ap.add_argument("--out_csv", default="data/repaired.csv", help="Output repaired CSV")
    ap.add_argument("--checkpoint", default="data/repair_checkpoint.json", help="Checkpoint file")
    ap.add_argument("--escalate_csv", default="data/escalate_list.csv", help="Escalation list")
    ap.add_argument("--max_retries", type=int, default=4, help="Max repair attempts per item")
    ap.add_argument("--only_soft_major", action="store_true", 
                    help="Only repair soft issues with major severity (skip minor)")
    ap.add_argument("--dry-run", action="store_true",
                    help="Validate configuration and count issues without making LLM calls")
    args = ap.parse_args()

    print(f"ğŸ”§ Starting Repair Loop v2.0...")
    print(f"   Input: {args.translated_csv}")
    print(f"   Hard QA: {args.qa_hard_report_json}")
    print(f"   Soft tasks: {args.repair_tasks_jsonl}")
    print(f"   Max retries: {args.max_retries}")
    if args.only_soft_major:
        print(f"   Mode: Only soft major (skip minor)")
    print()

    # Load resources
    rows = read_csv(args.translated_csv)
    
    hard = {}
    if Path(args.qa_hard_report_json).exists():
        hard = read_json(args.qa_hard_report_json)
    
    soft_tasks = iter_jsonl(args.repair_tasks_jsonl)
    
    style = load_text(args.style_guide_md)
    glossary_text = ""
    if args.glossary_yaml and Path(args.glossary_yaml).exists():
        glossary_text = load_text(args.glossary_yaml)

    # Build issue map: string_id -> [issues...]
    # Priority: hard errors first, then soft major
    issue_map: Dict[str, List[str]] = {}
    hard_ids = set()
    soft_major_ids = set()

    # 1) Hard QA errors (blocking - must fix)
    for e in (hard.get("errors") or []):
        sid = e.get("string_id", "")
        if sid:
            issue_map.setdefault(sid, []).append(
                f"hard:{e.get('type','')}:{e.get('detail','')[:120]}"
            )
            hard_ids.add(sid)

    # 2) Soft QA tasks (major only if --only_soft_major)
    for t in soft_tasks:
        sid = t.get("string_id", "")
        if not sid:
            continue
        sev = (t.get("severity") or "minor").lower()
        if args.only_soft_major and sev != "major":
            continue
        issue_map.setdefault(sid, []).append(
            f"soft:{t.get('type','')}:{t.get('note','')[:120]}"
        )
        if sev == "major":
            soft_major_ids.add(sid)

    print(f"âœ… Loaded {len(rows)} rows")
    print(f"âœ… Hard errors: {len(hard_ids)} strings")
    print(f"âœ… Soft major: {len(soft_major_ids)} strings")
    print(f"âœ… Total to repair: {len(issue_map)} strings")

    # Dry-run mode
    if getattr(args, 'dry_run', False):
        print()
        print("=" * 60)
        print("DRY-RUN MODE - Validation Summary")
        print("=" * 60)
        print()
        print(f"[OK] Input CSV: {len(rows)} rows")
        print(f"[OK] Style guide: {len(style)} chars")
        print(f"[OK] Glossary: {len(glossary_text)} chars")
        print(f"[OK] Hard errors to fix: {len(hard_ids)}")
        print(f"[OK] Soft issues to fix: {len(soft_major_ids)}")
        print(f"[OK] Total repair items: {len(issue_map)}")
        
        # Check LLM env
        import os
        llm_model = os.getenv("LLM_MODEL", "")
        if llm_model:
            print(f"[OK] LLM model: {llm_model}")
        else:
            print(f"[WARN] LLM_MODEL not set")
        
        print()
        print("=" * 60)
        print("[OK] Dry-run validation PASSED")
        if issue_map:
            print(f"     {len(issue_map)} items would be repaired in actual run")
        else:
            print(f"     No items need repair")
        print("=" * 60)
        return 0

    if not issue_map:
        print("\nâœ… No issues found. Nothing to repair.")
        # Still write out_csv identical for pipeline convenience
        if rows:
            write_csv(args.out_csv, list(rows[0].keys()), rows)
        return 0

    # Load checkpoint
    ckpt = load_checkpoint(args.checkpoint)
    done_ids = ckpt.get("done_ids", {})

    # Initialize LLM
    try:
        llm = LLMClient()
        print(f"âœ… Using LLM: {llm.default_model}")
    except LLMError as e:
        print(f"âŒ LLM Error: {e}")
        return 2

    print()

    fieldnames = list(rows[0].keys())
    if "target_text" not in fieldnames:
        raise ValueError("translated.csv must include target_text column")

    esc_fields = ["string_id", "reason", "tokenized_zh", "last_output"]

    # Build rows by id for in-place editing
    rows_by_id = {(r.get("string_id") or "").strip(): r for r in rows}
    
    # Get targets: hard first, then soft (order matters for priority)
    targets_hard = [sid for sid in hard_ids if not done_ids.get(sid, False)]
    targets_soft = [sid for sid in issue_map.keys() 
                    if sid not in hard_ids and not done_ids.get(sid, False)]
    targets = targets_hard + targets_soft

    ok = ckpt["stats"].get("ok", 0)
    fail = ckpt["stats"].get("fail", 0)

    print(f"ğŸš€ Processing {len(targets)} strings ({len(targets_hard)} hard, {len(targets_soft)} soft)...\n")

    for idx, sid in enumerate(targets, 1):
        row = rows_by_id.get(sid)
        if not row:
            print(f"  [{idx}/{len(targets)}] {sid}: âš ï¸  not found in CSV, skipping")
            continue

        issues = issue_map.get(sid, [])
        is_hard = sid in hard_ids
        priority = "HARD" if is_hard else "soft"
        
        print(f"  [{idx}/{len(targets)}] {sid} [{priority}]: repairing ({len(issues)} issues)...")

        system = build_system(style)
        user = build_user(row, issues, glossary_text)

        tokenized_zh = row.get("tokenized_zh") or row.get("source_zh") or ""
        current = row.get("target_text") or ""

        last_err = ""
        repaired_text = ""
        
        # Select step based on repair type for model routing
        repair_step = "repair_hard" if is_hard else "repair_soft_major"
        
        for attempt in range(args.max_retries + 1):
            try:
                result = llm.chat(system=system, user=user, temperature=0.1, metadata={"step": repair_step, "string_id": sid})
                
                # Direct text usage (Pure Text Strict Mode)
                cand = result.text.strip()
                
                # Clean up if model still output JSON-like quotes around text
                if cand.startswith('"') and cand.endswith('"'):
                    cand = cand[1:-1]
                
                okv, why = quick_validate(tokenized_zh, cand)
                
                if not okv:
                    last_err = why
                    raise ValueError(f"validation_failed:{why}")
                
                repaired_text = cand
                break
                
            except LLMError as e:
                last_err = f"{last_err} | {e.kind}:{e}".strip(" |")
                if not e.retryable:
                    break
                time.sleep(min(2 ** attempt, 20) * (0.5 + 0.5 * (idx % 3)))
            except Exception as e:
                last_err = f"{last_err} | {type(e).__name__}:{e}".strip(" |")
                time.sleep(min(2 ** attempt, 20) * (0.5 + 0.5 * (idx % 3)))
                if attempt >= args.max_retries:
                    break

        if not repaired_text:
            append_csv(args.escalate_csv, esc_fields, [{
                "string_id": sid,
                "reason": f"repair_failed_after_retries:{last_err}",
                "tokenized_zh": tokenized_zh,
                "last_output": current[:300],
            }])
            fail += 1
            print(f"    âŒ escalated: {last_err[:60]}")
        else:
            rows_by_id[sid]["target_text"] = repaired_text
            ok += 1
            done_ids[sid] = True
            print(f"    âœ… repaired")

        # Save checkpoint periodically
        ckpt["done_ids"] = done_ids
        ckpt["stats"] = {"ok": ok, "fail": fail}
        save_checkpoint(args.checkpoint, ckpt)

        if idx % 50 == 0:
            print(f"\n  [PROGRESS] {idx}/{len(targets)} ok={ok} fail={fail}\n")

    # Write repaired file (full CSV with all rows, repaired in-place)
    repaired_rows = list(rows_by_id.values())
    write_csv(args.out_csv, fieldnames, repaired_rows)

    # Summary
    print()
    print(f"ğŸ“Š Repair Loop Summary:")
    print(f"   Total targets: {len(targets)}")
    print(f"   Hard errors: {len(targets_hard)}")
    print(f"   Soft issues: {len(targets_soft)}")
    print(f"   Repaired: {ok}")
    print(f"   Failed: {fail}")

    print()
    print(f"âœ… Output: {args.out_csv}")
    if fail > 0:
        print(f"âš ï¸  Escalated: {args.escalate_csv}")
    print()
    print("âœ… Repair loop complete!")

    return 0


if __name__ == "__main__":
    exit(main())
