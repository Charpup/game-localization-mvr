# Loc-mvr v1.2.0 Release Notes

**Release Date:** February 14, 2026  
**Package:** `loc-mvr-v1.2.0.skill` (296 KB)  
**SHA256:** See `loc-mvr-v1.2.0.skill.sha256`

---

## ðŸŽ‰ Major Features

### 1. ðŸ§  Intelligent Model Router
- **Smart Complexity Analysis**: Automatically analyzes text complexity based on:
  - Text length (20% weight)
  - Placeholder density (25% weight)
  - Glossary term density (25% weight)
  - Special character density (15% weight)
  - Historical failure patterns (15% weight)
- **Cost Optimization**: Routes simple text to cheaper models (GPT-3.5, GPT-4.1-nano) and complex content to premium models (GPT-4, Claude Sonnet)
- **Learning System**: Tracks QA failure patterns to continuously improve routing decisions
- **Expected Savings**: 20-40% cost reduction on typical workloads

**Files:** `scripts/model_router.py`, `config/model_routing.yaml`, `tests/test_model_router.py`

### 2. âš¡ Async/Concurrent Execution Engine
- **Async LLM Client**: Concurrent API calls with semaphore-based rate limiting
- **Streaming Pipeline**: Overlapping pipeline stages (normalize â†’ translate â†’ QA â†’ export)
- **Backpressure Handling**: Prevents memory overflow under heavy load
- **Configurable Concurrency**: Per-stage limits optimized for I/O vs CPU-bound operations
- **Performance**: 2-3x throughput improvement (50-100 rows/sec vs 20-30 rows/sec)

**Files:** `scripts/async_adapter.py`, `scripts/batch_runtime.py`, `scripts/runtime_adapter.py`, `tests/test_async_adapter.py`, `tests/test_runtime_adapter_v2.py`

### 3. ðŸ“š Glossary AI System
- **Glossary Matcher**: Fuzzy matching with 95%+ auto-approval rate for high-confidence matches
- **Glossary Corrector**: Detects and suggests fixes for glossary violations, spelling errors, case issues
- **Glossary Learner**: Russian declension support with case ending handling
- **Context Validation**: Disambiguates homonyms using surrounding context

**Files:** `scripts/glossary_matcher.py`, `scripts/glossary_corrector.py`, `scripts/glossary_learner.py`, `tests/test_glossary_matcher.py`, `tests/test_glossary_corrector.py`, `tests/test_glossary_learner.py`

### 4. ðŸ’¾ Enhanced Response Caching
- **SQLite-based Cache**: Persistent storage with TTL support (default 7 days)
- **LRU Eviction**: Automatic cleanup when size limit reached
- **Cache Analytics**: Real-time hit/miss tracking with cost savings calculation
- **Cost Savings**: 50%+ reduction on repeated translations

**Files:** `scripts/cache_manager.py`, `tests/test_cache_manager.py`

---

## ðŸ“Š Performance Improvements

| Metric | v1.1.0 | v1.2.0 | Improvement |
|--------|--------|--------|-------------|
| Throughput (rows/sec) | 20-30 | 50-100 | 2-3x |
| Avg Cost per 1k rows | $1.50 | $0.90-1.20 | 20-40% â†“ |
| Glossary Match Accuracy | 85% | 95%+ | +10% |
| Cache Hit Rate | 60% | 75% | +15% |
| First Translation Latency | 120s | 80s | 33% â†“ |

---

## ðŸ“ Package Contents

```
v1.2.0/
â”œâ”€â”€ SKILL.md                      # Skill documentation
â”œâ”€â”€ MANIFEST.txt                  # Package manifest
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ config/                       # Configuration files
â”‚   â”œâ”€â”€ pipeline.yaml             # Pipeline configuration
â”‚   â”œâ”€â”€ model_routing.yaml        # Model routing rules
â”‚   â”œâ”€â”€ llm_routing.yaml          # LLM routing configuration
â”‚   â”œâ”€â”€ cost_monitoring.yaml      # Cost monitoring settings
â”‚   â”œâ”€â”€ length_rules.yaml         # Text length rules
â”‚   â”œâ”€â”€ pricing.yaml              # Model pricing data
â”‚   â”œâ”€â”€ repair_config.yaml        # Repair loop configuration
â”‚   â””â”€â”€ punctuation/              # Punctuation rules
â”‚       â”œâ”€â”€ base.yaml
â”‚       â””â”€â”€ ru-RU.yaml
â”œâ”€â”€ scripts/                      # Core scripts (32 modules)
â”‚   â”œâ”€â”€ model_router.py           # Intelligent model routing
â”‚   â”œâ”€â”€ async_adapter.py          # Async execution engine
â”‚   â”œâ”€â”€ batch_runtime.py          # Batch processing runtime
â”‚   â”œâ”€â”€ runtime_adapter.py        # Runtime adaptation layer
â”‚   â”œâ”€â”€ cache_manager.py          # Response caching
â”‚   â”œâ”€â”€ glossary_matcher.py       # Glossary matching
â”‚   â”œâ”€â”€ glossary_corrector.py     # Glossary correction
â”‚   â”œâ”€â”€ glossary_learner.py       # Glossary learning
â”‚   â”œâ”€â”€ translate_llm.py          # Translation engine
â”‚   â”œâ”€â”€ normalize_guard.py        # Placeholder protection
â”‚   â”œâ”€â”€ qa_hard.py                # Hard QA validation
â”‚   â”œâ”€â”€ qa_soft.py                # Soft QA validation
â”‚   â”œâ”€â”€ repair_loop_v2.py         # Auto-repair system
â”‚   â”œâ”€â”€ extract_terms.py          # Term extraction
â”‚   â”œâ”€â”€ rehydrate_export.py       # Export with placeholder restoration
â”‚   â””â”€â”€ ... (18 more modules)
â”œâ”€â”€ tests/                        # Test suite (19 test files)
â”‚   â”œâ”€â”€ test_model_router.py
â”‚   â”œâ”€â”€ test_async_adapter.py
â”‚   â”œâ”€â”€ test_cache_manager.py
â”‚   â”œâ”€â”€ test_glossary_*.py
â”‚   â”œâ”€â”€ test_v1_2_0_integration.py
â”‚   â”œâ”€â”€ benchmark_v1_2_0.py
â”‚   â””â”€â”€ ... (12 more test files)
â”œâ”€â”€ examples/                     # Usage examples
â”‚   â”œâ”€â”€ example_usage.py
â”‚   â”œâ”€â”€ batch_usage_example.py
â”‚   â”œâ”€â”€ sample_input.csv
â”‚   â””â”€â”€ sample_glossary.yaml
â”œâ”€â”€ workflow/                     # Workflow configurations
â”‚   â”œâ”€â”€ placeholder_schema.yaml   # Placeholder definitions
â”‚   â”œâ”€â”€ llm_config.yaml          # LLM configuration
â”‚   â”œâ”€â”€ soft_qa_rubric.yaml      # QA rubric
â”‚   â””â”€â”€ forbidden_patterns.txt   # Forbidden pattern list
â””â”€â”€ docs/                         # Documentation
    â””â”€â”€ README.md
```

---

## ðŸ”§ New Configuration Files

### config/model_routing.yaml
```yaml
routing:
  default_model: "gpt-4o-mini"
  complexity_thresholds:
    simple: 0.3
    medium: 0.6
    complex: 0.8
  
  model_map:
    simple: "gpt-4.1-nano"
    medium: "gpt-4o-mini"
    complex: "gpt-4o"
    critical: "claude-sonnet-4-20250514"
```

### config/llm_routing.yaml
Configuration for LLM provider routing with fallback chains.

### config/cost_monitoring.yaml
Real-time cost tracking and alerting configuration.

---

## ðŸš€ Quick Start

```bash
# 1. Download and extract
wget https://github.com/Charpup/game-localization-mvr/releases/download/v1.2.0/loc-mvr-v1.2.0.skill
unzip loc-mvr-v1.2.0.skill

# 2. Verify checksum
sha256sum -c loc-mvr-v1.2.0.skill.sha256

# 3. Install dependencies
cd v1.2.0
pip install -r requirements.txt

# 4. Run with intelligent routing
python scripts/translate_llm.py \
  --input data/input.csv \
  --output data/output.csv \
  --smart-routing

# 5. Or run with async processing
python scripts/async_adapter.py \
  --input data/input.csv \
  --output data/output.csv \
  --max-concurrent 10
```

---

## ðŸ§ª Testing

```bash
# Run all tests
pytest tests/ -v

# Run specific test suite
pytest tests/test_model_router.py -v
pytest tests/test_async_adapter.py -v
pytest tests/test_glossary_matcher.py -v

# Run benchmark
python tests/benchmark_v1_2_0.py
```

---

## ðŸ“ API Changes

### New Classes

**ModelRouter**
```python
from scripts.model_router import ModelRouter

router = ModelRouter()
model, metrics, cost = router.select_model(
    text="Your text here",
    glossary_terms=["term1", "term2"]
)
```

**AsyncAdapter**
```python
from scripts.async_adapter import process_csv_async
import asyncio

stats = asyncio.run(process_csv_async(
    input_path="data/input.csv",
    output_path="data/output.csv",
    max_concurrent=10
))
```

**GlossaryMatcher**
```python
from scripts.glossary_matcher import GlossaryMatcher

matcher = GlossaryMatcher()
matches = matcher.find_matches("Source text")
```

**CacheManager**
```python
from scripts.cache_manager import CacheManager

cache = CacheManager()
stats = cache.get_stats()
```

---

## ðŸ› Bug Fixes

- Fixed placeholder leakage in long text segments
- Improved handling of nested HTML/Unity tags
- Fixed token limit exceeded errors for texts >500 chars
- Resolved model routing confusion between haiku/sonnet
- Fixed cache analytics not tracking hit rates correctly

---

## ðŸ“ˆ Production Verification

- âœ… **30k+ rows validated**: $48.44 cost, 99.87% accuracy
- âœ… **Multi-model support**: GPT-4o, Claude Sonnet, Haiku, Kimi-k2.5
- âœ… **Dockerized**: Consistent environment with API key injection
- âœ… **Response Caching**: 50%+ cost reduction on repeated content
- âœ… **Intelligent Routing**: 20-40% additional cost savings
- âœ… **Async Processing**: 30-50% latency reduction
- âœ… **Glossary AI**: 95%+ auto-approval rate for glossary matches

---

## ðŸ”— Resources

- **GitHub Repository:** https://github.com/Charpup/game-localization-mvr
- **Full Documentation:** See `SKILL.md` in extracted package
- **Issue Tracker:** https://github.com/Charpup/game-localization-mvr/issues
- **Changelog:** See `CHANGELOG.md`

---

## ðŸ“„ License

MIT License - See `LICENSE` file for details.

---

**Need LLM API?** Try [APIYi](https://api.apiyi.com/register/?aff_code=8Via)
